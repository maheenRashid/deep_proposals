require 'nn';
require 'loadcaffe';
require 'cutorch';
require 'cunn';
require 'optim'
require 'hdf5'
require 'image'
require 'gnuplot'
npy4th = require 'npy4th'
require 'data_withFlow';
require 'paths';

function makeMyNetwork(torch_file)


	local vgg=torch.load(torch_file);
    vgg=vgg:double();

    local para=nn.ParallelTable();
    para:add(vgg);
    para:add(vgg:clone());
    
    local seq=nn.Sequential();
    seq:add(para);

    local seq_trunk = nn.Sequential();
    seq_trunk:add(nn.JoinTable(2));
    seq_trunk:add(nn.SpatialConvolution(1024,512,1,1));
    seq_trunk:add(nn.SpatialConvolution(512,128,1,1));
    seq_trunk:add(nn.View(128*10*10));
    seq_trunk:add(nn.Linear(128*10*10,512));

    for idx=1,#seq_trunk do
        if seq_trunk:get(idx).weight then
            seq_trunk:get(idx).weight=torch.randn(seq_trunk:get(idx).weight:size()):div(100);
        end
        if seq_trunk:get(idx).bias then
            seq_trunk:get(idx).bias=torch.zeros(seq_trunk:get(idx).bias:size());
        end
    end
    -- make the combination conv unit weights
    -- seq_trunk:get(2).weight=torch.ones(seq_trunk:get(2).weight:size());
    -- seq_trunk:get(2).bias=torch.zeros(seq_trunk:get(2).bias:size());
	seq:add(seq_trunk);



	local score_branch=nn.Sequential();
	score_branch:add(nn.Linear(512,1024));
	score_branch:add(nn.ReLU());
	score_branch:add(nn.Dropout(0.5));
	score_branch:add(nn.Linear(1024,1));
	
    for idx=1,#score_branch do
        if score_branch:get(idx).weight then
            score_branch:get(idx).weight=torch.randn(score_branch:get(idx).weight:size()):div(100);
        end
        if score_branch:get(idx).bias then
            score_branch:get(idx).bias=torch.zeros(score_branch:get(idx).bias:size());
        end
    end

	local seg_branch=nn.Sequential();
	seg_branch:add(nn.Linear(512,40*40));
	seg_branch:add(nn.View(1,40,40));
	seg_branch:add(nn.SpatialUpSamplingNearest(4));
	
    for idx=1,#seg_branch do
        if seg_branch:get(idx).weight then
            seg_branch:get(idx).weight=torch.randn(seg_branch:get(idx).weight:size()):div(100);
        end
        if seg_branch:get(idx).bias then
            seg_branch:get(idx).bias=torch.zeros(seg_branch:get(idx).bias:size());
        end
    end

	local split_net=nn.ConcatTable();
	split_net:add(score_branch);
	split_net:add(seg_branch);

    local total_net = nn.Sequential();
    total_net:add(seq);
    total_net:add(split_net);

	return total_net
end

function getLossSeg(x_seg,gt_mask)
	local loss=torch.mul(gt_mask,-1)
	-- print(loss:size())
	-- print(gt_mask:size())
	loss:cmul(x_seg)
	loss:exp();
	loss:add(1);
	loss:log();
    loss:div(56*56);
	loss=loss:sum()
	return loss;
end

function getLossScore(x_score,gt_label)
    local loss=torch.mul(gt_label,-1)
    loss:cmul(x_score)
    loss:exp();
    loss:add(1);
    loss:log();
    loss:div(32);
    loss=loss:sum()
    return loss;
end

function getLossSegD(x_seg,gt_mask)
	local dloss=torch.mul(gt_mask,-1);
	dloss:cmul(x_seg);
	dloss:exp();
	local deno=torch.add(dloss,1);
	dloss:cmul(gt_mask);
	dloss:mul(-1);
	dloss:cdiv(deno);
	dloss:div(56*56);
	return dloss;
end

function getLossScoreD(x_score,gt_label)
	-- print (x_score)
	local dloss=torch.mul(gt_label,-1);
	dloss:cmul(x_score);
    dloss:exp();
    local deno=torch.add(dloss,1);
    dloss:cmul(gt_label);
    dloss:mul(-1);
    dloss:cdiv(deno);
    dloss:div(32);
    return dloss;
end

local torch_file='/disk2/januaryExperiments/vgg_16/vgg16_onlyConv.dat';
local deep_prop_file='/disk2/aprilExperiments/headC_160/withFlow_gaussian_all.dat'
local out_dir='/disk3/maheen_data/headC_160/withFlow_gaussian_human';

-- net=makeMyNetwork(torch_file)
-- print (net)
-- torch.save(deep_prop_file,net);
-- net=torch.load(deep_prop_file);
-- print (net);
-- print (net:get(1):get(2):get(2))
-- print (torch.min(net:get(1):get(2):get(2).weight),torch.min(net:get(1):get(2):get(2).bias),
--     torch.min(net:get(1):get(2):get(3).weight),torch.min(net:get(1):get(2):get(3).bias));


local neg_file='/disk3/maheen_data/headC_160/neg_flos/negatives_onlyHuman_withFlow.txt'
local pos_file='/disk3/maheen_data/headC_160/noFlow_gaussian_human/pos_flos/positives_onlyHuman_withFlow.txt'

paths.mkdir(out_dir);
local out_dir_intermediate=paths.concat(out_dir,'intermediate');
local out_dir_final=paths.concat(out_dir,'final');
paths.mkdir(out_dir_intermediate);
paths.mkdir(out_dir_final);

local out_file_net=out_dir_final..'/'..'model_all_final.dat';

local out_file_loss_seg=out_dir_final..'/'..'loss_all_final_seg.npy';
local out_file_loss_score=out_dir_final..'/'..'loss_all_final_score.npy';

local out_file_intermediate_pre = out_dir_intermediate..'/'..'model_all_';
local out_file_loss_intermediate_pre = out_dir_intermediate..'/'..'loss_all_';

local out_file_loss_plot_intermediate_score=out_dir_intermediate..'/'..'loss_iter_score.png';
local out_file_loss_plot_final_score=out_dir_final..'/'..'loss_iter_score.png';

local out_file_loss_plot_intermediate_seg=out_dir_intermediate..'/'..'loss_iter_seg.png';
local out_file_loss_plot_final_seg=out_dir_final..'/'..'loss_iter_seg.png';


-- print ('pos_file',pos_file)
-- print ('neg_file',neg_file)
-- td=data({file_path_positive=pos_file,file_path_negative=neg_file});
-- print (td.lines_positive[1])
-- print (td.lines_negative[1])
-- -- td:getTrainingDataToy();
-- td:getTrainingDataToyScore();
-- print (td.training_set_score.data:size())
-- for i=1,td.training_set_score.data:size(1) do
--     print (i,torch.min(td.training_set_score.data[i]),torch.max(td.training_set_score.data[i]),
    -- td.training_set_score.label[i][1])
-- end



local opt = {}         
opt.optimization = 'sgd'
opt.batch_size=32;
opt.learningRate=0.001;
opt.momentum=0.9
opt.weightDecay=0.00005;
opt.iterations=100000;
opt.saveAfter=5000;
opt.plotAfter=50;
opt.dispAfter=4;

cutorch.setDevice(1);

local optimState       
local optimMethod      

optimState = {
    learningRate = opt.learningRate,
    weightDecay = opt.weightDecay,
    momentum = opt.momentum,
}

optimMethod = optim.sgd


print ('loading network');

net = torch.load(deep_prop_file);
-- net:get(2):get(2):add(nn.Tanh())
print (torch.min(net:get(1):get(2):get(3).weight),torch.min(net:get(1):get(2):get(3).weight));

print ('done loading network');
-- print (net:get(1));
print (net);

print ('making cuda');
net = net:cuda();
print ('done');

print ('loading params');
local parameters, gradParameters = net:getParameters()
print ('loading done');
print (optimState)
print ('pos_file',pos_file)
print ('neg_file',neg_file)
td=data({file_path_positive=pos_file,file_path_negative=neg_file});

local counter = 0

local fevalScore = function(x)
    if x ~= parameters then
    parameters:copy(x)
    end
    
    td:getTrainingDataToyScore();    
    local batch_inputs = td.training_set_score.data:cuda();
    local batch_inputs_flow = td.training_set_score.flo:cuda();
    local batch_targets = td.training_set_score.label:cuda();
    
    gradParameters:zero()
    
    local batch_outputs_mid = net:get(1):forward{batch_inputs,batch_inputs_flow}
    local batch_outputs = net:get(2):get(1):forward(batch_outputs_mid)

    local batch_loss = getLossScore(batch_outputs, batch_targets)
    local dloss_doutput = getLossScoreD(batch_outputs, batch_targets)
    local gradInputs=net:get(2):get(1):backward(batch_outputs_mid, dloss_doutput)
    net:get(1):backward(batch_inputs, gradInputs)
    return batch_loss, gradParameters
end


local fevalSeg = function(x)
    if x ~= parameters then
    parameters:copy(x)
    end
    
    td:getTrainingDataToy();    
    local batch_inputs = td.training_set_seg.data:cuda();
    local batch_inputs_flow = td.training_set_seg.flo:cuda();
    local batch_targets = td.training_set_seg.label:cuda();

    gradParameters:zero()
    local batch_outputs_mid = net:get(1):forward{batch_inputs,batch_inputs_flow}
    local batch_outputs = net:get(2):get(2):forward(batch_outputs_mid)
    local batch_loss = getLossSeg(batch_outputs, batch_targets)
    local dloss_doutput = getLossSegD(batch_outputs, batch_targets)
    
    local gradInputs=net:get(2):get(2):backward(batch_outputs_mid, dloss_doutput):clone()
    net:get(1):backward(batch_inputs, gradInputs)
    return batch_loss, gradParameters
end


local losses_seg = {};
local losses_score = {};

for i=1,opt.iterations do
    
    if i%2==0 then
        local _, minibatch_loss = optimMethod(fevalScore,parameters, optimState)
        losses_score[#losses_score + 1] = minibatch_loss[1] -- append the new loss        
    else
        local _, minibatch_loss = optimMethod(fevalSeg,parameters, optimState)
        losses_seg[#losses_seg + 1] = minibatch_loss[1] -- append the new loss

    end

    if i%opt.dispAfter==0 then
        print(string.format("minibatches processed: %6s, loss seg = %6.6f, loss score = %6.6f", i, 
            losses_seg[#losses_seg],losses_score[#losses_score]))
    end

    -- check if model needs to be saved. save it.
    -- also save losses
    if i%opt.saveAfter==0 then
        local out_file_intermediate=out_file_intermediate_pre..i..'.dat';
        torch.save(out_file_intermediate,net);
        local out_file_loss_intermediate=out_file_loss_intermediate_pre..i..'_score.npy';
        npy4th.savenpy(out_file_loss_intermediate, torch.Tensor(losses_score))
        local out_file_loss_intermediate=out_file_loss_intermediate_pre..i..'_seg.npy';
        npy4th.savenpy(out_file_loss_intermediate, torch.Tensor(losses_seg))
    end
    
    -- check if losses need to be plotted. plot them.
    -- if i%opt.plotAfter==0 then
        
    --     gnuplot.pngfigure(out_file_loss_plot_intermediate_score)
    --     local iteration_score = torch.range( 1, #losses_score)
    --     gnuplot.plot({'Score Loss', iteration_score, torch.Tensor(losses_score),  '-'})
    --     gnuplot.xlabel('Iterations')
    --     gnuplot.ylabel('Loss')
    --     gnuplot.plotflush()

    --     gnuplot.pngfigure(out_file_loss_plot_intermediate_seg)
    --     local iteration_seg = torch.range( 1, #losses_seg)
    --     gnuplot.plot({'Segmentation Loss', iteration_seg, torch.Tensor(losses_seg), '-'})
    --     gnuplot.xlabel('Iterations')
    --     gnuplot.ylabel('Loss')
    --     gnuplot.plotflush()
    -- end

end

-- save final model
torch.save(out_file_net,net);
npy4th.savenpy(out_file_loss_seg, torch.Tensor(losses_seg))
npy4th.savenpy(out_file_loss_score, torch.Tensor(losses_score))

-- save final plot

-- gnuplot.pngfigure(out_file_loss_plot_final_score)
-- local iteration_score = torch.range( 1, #losses_score)
-- gnuplot.plot({'Score Loss', iteration_score, torch.Tensor(losses_score),  '-'})
-- gnuplot.xlabel('Iterations')
-- gnuplot.ylabel('Loss')
-- gnuplot.plotflush()

-- gnuplot.pngfigure(out_file_loss_plot_final_seg)
-- local iteration_seg = torch.range( 1, #losses_seg)
-- gnuplot.plot({'Segmentation Loss', iteration_seg, torch.Tensor(losses_seg), '-'})
-- gnuplot.xlabel('Iterations')
-- gnuplot.ylabel('Loss')
-- gnuplot.plotflush()
